{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "#Import files module\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re                     ##Regular expressions\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import datetime\n",
    "#from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logging mechanism for debugging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mapping months to numeric values\n",
    "months = {'01':'Jan','02':'Feb','03':'Mar','04':'Apr','05':'May','06':'June','07':'July','08':'Aug','09':'Sept','10':'Oct','11':'Nov','12':'Dec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''path = r'D:\\Dharmit\\Final Year Project\\Clean data Vikhroli\\0071\\Up' \n",
    "allfiles = glob.glob(path + \"/*.csv\")\n",
    "Holiday_colnames = ['Holiday', 'Date', 'Day', 'Month']\n",
    "Holiday_data = pd.read_csv('D:\\Dharmit\\Final Year Project\\List of holidays.csv', names=Holiday_colnames)\n",
    "feature_names =  ['Time Slot','Trips','Passengers','Day','isHoliday']'''\n",
    "\n",
    "#Importing files from specific folders and list of holidays\n",
    "bus_no='3860'\n",
    "path = r'D:/Dharmit/Final Year Project/Clean data Vikhroli/'+bus_no+'/Up' \n",
    "down_path = r'D:/Dharmit/Final Year Project/Clean data Vikhroli/'+bus_no+'/Down' \n",
    "allfiles = glob.glob(path + \"/*.csv\")\n",
    "down_allfiles=glob.glob(down_path + \"/*.csv\")\n",
    "Holiday_colnames = ['Holiday', 'Date', 'Day', 'Month']\n",
    "Holiday_data = pd.read_csv('D:\\Dharmit\\Final Year Project\\List of holidays.csv', names=Holiday_colnames)\n",
    "Holiday_2017 = pd.read_csv('D:\\Dharmit\\Final Year Project\\List of holidays 2017.csv', names=Holiday_colnames)\n",
    "feature_names =  ['Time Slot','Trips','Passengers','Day','isHoliday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making separate dataframes for each separate timeslot over many days\n",
    "df1=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df2=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df3=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df4=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df5=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df6=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df7=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df8=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df9=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df10=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df11=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df12=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df13=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df14=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df15=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df16=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df17=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df18=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df19=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df20=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df=[df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20]\n",
    "\n",
    "#Dicing only requird data from list of holidays\n",
    "holiday_day = Holiday_data['Day']\n",
    "holiday_month = Holiday_data['Month']\n",
    "holiday_day_2017 = Holiday_2017['Day']\n",
    "holiday_month_2017 = Holiday_2017['Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Timeslot_values= ['00:00:01-05:00:00','05:00:01-06:00:00','06:00:01-07:00:00','07:00:01-08:00:00','08:00:01-09:00:00','09:00:01-10:00:00','10:00:01-11:00:00','11:00:01-12:00:00','12:00:01-13:00:00','13:00:01-14:00:00','14:00:01-15:00:00','15:00:01-16:00:00','16:00:01-17:00:00','17:00:01-18:00:00','18:00:01-19:00:00','19:00:01-20:00:00','20:00:01-21:00:00','21:00:01-22:00:00','22:00:01-23:00:00','23:00:01-24:00:00']\n",
    "Days = {'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}\n",
    "\n",
    "#Obtaining the day and date details for current day \n",
    "now = datetime.datetime.now()   \n",
    "current_month = months[str(now.month).zfill(2)] \n",
    "current_day = now.day\n",
    "isCurrDay_holiday = 0\n",
    "current_dow = Days[now.strftime(\"%A\")]           #Obtaining current day of the week\n",
    "for i in range(1,23):                            #checking if there is holiday today\n",
    "    if(holiday_day[i]==current_day and current_month==holiday_month[i]):\n",
    "        isCurrDay_holiday=1\n",
    "\n",
    "for files in allfiles:\n",
    "    #Obtaining Day and date details from filename\n",
    "    base = os.path.basename(files)\n",
    "    day = os.path.splitext(base)[0][29:]\n",
    "    date = os.path.splitext(base)[0][26:28]\n",
    "\n",
    "    month = os.path.splitext(base)[0][23:25]\n",
    "    year = os.path.splitext(base)[0][18:22]\n",
    "    #Determining whether holiday or not\n",
    "    holiday = 0\n",
    "    if year=='2017':\n",
    "        for i in range(1,22):\n",
    "            if(str(holiday_day_2017[i]).zfill(2)==date and months[month]==holiday_month_2017[i]):\n",
    "            #print'Holiday 2017'\n",
    "                holiday=1\n",
    "    else:\n",
    "        for i in range(1,23):\n",
    "            if(holiday_day[i]==date and months[month]==holiday_month[i]):\n",
    "                holiday=1\n",
    "            \n",
    "    #Pre-processing data into required format\n",
    "    day = Days[day]                                        #Mapping day to numeric value\n",
    "    with open(files,'rb') as f:\n",
    "        timeslot = []\n",
    "        trips = []\n",
    "        passengers = []\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        rows = [r for r in reader]\n",
    "        for x in rows[1:]:\n",
    "            timeslot.append(x[1])\n",
    "            trips.append(x[2])\n",
    "            if(x[3]==''):\n",
    "                x[3]=0\n",
    "            passengers.append(x[3])\n",
    " \n",
    "    #Adding data into the dataframes created previously according to time slots\n",
    "    for j in xrange(len(timeslot)):\n",
    "        df[j]= df[j].append(pd.Series([timeslot[j],trips[j],int(passengers[j]),day,holiday], index = ['Time Slot','Trips','Passengers','Day','isHoliday']), ignore_index=True)\n",
    "        df[j]=df[j].replace('',0)                      #Replacing NAN values by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Time Slot Trips  Passengers  Day  isHoliday\n",
      "0    10:00:01-11:00:00     4          19    7          1\n",
      "1    10:00:01-11:00:00     2          29    1          1\n",
      "2    10:00:01-11:00:00     5         164    2          0\n",
      "3    10:00:01-11:00:00     4         155    3          0\n",
      "4    10:00:01-11:00:00     6         399    4          0\n",
      "5    10:00:01-11:00:00     2         112    5          0\n",
      "6    10:00:01-11:00:00     2         121    6          0\n",
      "7    10:00:01-11:00:00     2          50    7          0\n",
      "8    10:00:01-11:00:00     3         202    1          0\n",
      "9    10:00:01-11:00:00     6         302    2          0\n",
      "10   10:00:01-11:00:00     4         178    3          0\n",
      "11   10:00:01-11:00:00     3         182    4          0\n",
      "12   10:00:01-11:00:00     3         138    5          0\n",
      "13   10:00:01-11:00:00     3          88    6          0\n",
      "14   10:00:01-11:00:00     2          39    7          0\n",
      "15   10:00:01-11:00:00     4         184    1          0\n",
      "16   10:00:01-11:00:00     6         149    2          0\n",
      "17   10:00:01-11:00:00     4         166    3          0\n",
      "18   10:00:01-11:00:00     3          37    4          1\n",
      "19   10:00:01-11:00:00     5          63    5          1\n",
      "20   10:00:01-11:00:00     5          27    6          0\n",
      "21   10:00:01-11:00:00     2          22    7          0\n",
      "22   10:00:01-11:00:00     4          95    1          0\n",
      "23   10:00:01-11:00:00     3         225    2          0\n",
      "24   10:00:01-11:00:00     3         260    3          0\n",
      "25   10:00:01-11:00:00     3         142    4          0\n",
      "26   10:00:01-11:00:00     4         181    5          0\n",
      "27   10:00:01-11:00:00     3          63    6          0\n",
      "28   10:00:01-11:00:00     4          34    7          0\n",
      "29   10:00:01-11:00:00     4         192    1          0\n",
      "..                 ...   ...         ...  ...        ...\n",
      "102  10:00:01-11:00:00     3          69    4          0\n",
      "103  10:00:01-11:00:00     1          80    1          0\n",
      "104  10:00:01-11:00:00     3         116    2          0\n",
      "105  10:00:01-11:00:00     3          86    5          0\n",
      "106  10:00:01-11:00:00     2          27    6          0\n",
      "107  10:00:01-11:00:00     3          23    7          0\n",
      "108  10:00:01-11:00:00     4         142    1          0\n",
      "109  10:00:01-11:00:00     4         134    2          0\n",
      "110  10:00:01-11:00:00     2          34    3          0\n",
      "111  10:00:01-11:00:00     1           7    4          0\n",
      "112  10:00:01-11:00:00     3          17    5          1\n",
      "113  10:00:01-11:00:00     2          30    6          0\n",
      "114  10:00:01-11:00:00     3          25    7          0\n",
      "115  10:00:01-11:00:00     2          75    1          0\n",
      "116  10:00:01-11:00:00     1          69    2          0\n",
      "117  10:00:01-11:00:00     3         135    3          0\n",
      "118  10:00:01-11:00:00     1          43    4          0\n",
      "119  10:00:01-11:00:00     2          78    5          0\n",
      "120  10:00:01-11:00:00     1          24    6          0\n",
      "121  10:00:01-11:00:00     1           7    7          0\n",
      "122  10:00:01-11:00:00     3          90    1          0\n",
      "123  10:00:01-11:00:00     3          96    2          0\n",
      "124  10:00:01-11:00:00     2         121    3          0\n",
      "125  10:00:01-11:00:00     3          80    4          0\n",
      "126  10:00:01-11:00:00     3          62    5          0\n",
      "127  10:00:01-11:00:00     1           5    6          0\n",
      "128  10:00:01-11:00:00     3          31    7          0\n",
      "129  10:00:01-11:00:00     2          51    1          0\n",
      "130  10:00:01-11:00:00     3          72    2          1\n",
      "131  10:00:01-11:00:00     1          65    3          0\n",
      "\n",
      "[132 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print df[6]                                       #To check whether data has been successfully pre-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(20):\n",
    "    for j in xrange(len(df[i]['Time Slot'])):\n",
    "        df[i]['Time Slot'][j]=int(df[i]['Time Slot'][j][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time Slot Trips  Passengers  Day  isHoliday\n",
      "0         10     0         150    4          0\n",
      "1         10     2         127    1          0\n",
      "2         10     1         207    5          0\n",
      "3         10     0         132    2          0\n",
      "4         10     2         155    6          0\n",
      "5         10     2         124    3          0\n",
      "6         10     1          93    7          0\n",
      "7         10     0         171    4          0\n",
      "8         10     0         181    1          0\n",
      "9         10     0         135    5          0\n",
      "10        10     1          98    2          0\n",
      "11        10     1         162    6          0\n",
      "12        10     1         155    3          0\n",
      "13        10     0           9    7          0\n",
      "14        10     1         152    4          0\n",
      "15        10     0          90    1          0\n",
      "16        10     2         238    5          0\n",
      "17        10     2         212    2          0\n",
      "18        10     1         195    6          0\n",
      "19        10     1         173    3          0\n",
      "20        10     2          43    7          0\n",
      "21        10     1          50    4          0\n",
      "22        10     1         134    1          0\n",
      "23        10     2         127    2          1\n",
      "24        10     2         155    3          0\n",
      "25        10     1         155    1          0\n",
      "26        10     0         168    2          0\n",
      "27        10     1         193    5          0\n",
      "28        10     2         136    6          0\n",
      "29        10     0           0    7          0\n",
      "30        10     0         135    1          0\n",
      "31        10     1          84    2          0\n",
      "32        10     1         110    3          0\n",
      "33        10     1         112    4          0\n",
      "34        10     2          73    5          1\n",
      "35        10     1         147    6          0\n",
      "36        10     1          87    7          0\n",
      "37        10     2         185    1          0\n",
      "38        10     0         133    2          0\n",
      "39        10     1         210    3          0\n"
     ]
    }
   ],
   "source": [
    "print df[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35   4   0]\n",
      " [148   1   0]\n",
      " [173   5   0]\n",
      " [  0   2   0]\n",
      " [ 49   6   0]\n",
      " [  0   3   0]\n",
      " [144   7   0]\n",
      " [ 82   4   0]\n",
      " [129   1   0]\n",
      " [102   5   0]\n",
      " [123   2   0]\n",
      " [138   6   0]\n",
      " [ 73   3   0]\n",
      " [ 69   7   0]\n",
      " [ 63   4   0]\n",
      " [ 50   1   0]\n",
      " [ 92   5   0]\n",
      " [118   2   0]\n",
      " [ 79   6   0]\n",
      " [159   3   0]\n",
      " [ 65   7   0]\n",
      " [162   4   0]\n",
      " [ 97   1   0]\n",
      " [117   2   1]\n",
      " [ 79   3   0]\n",
      " [138   1   0]\n",
      " [102   2   0]\n",
      " [111   5   0]\n",
      " [183   6   0]\n",
      " [ 56   7   0]\n",
      " [ 89   1   0]\n",
      " [112   2   0]] ['1' '1' '0' '0' '1' 0 '2' '1' '0' '1' '2' '1' '0' '1' '1' '2' '1' '0' '1'\n",
      " '3' '2' '0' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '4' '3'\n",
      " '1' '1' '0']\n"
     ]
    }
   ],
   "source": [
    "train_all_features = df[10][feature_names][:32].drop(['Trips','Time Slot'], axis=1).values\n",
    "test_all_features=df[10][feature_names][32:].drop(['Trips','Time Slot'], axis=1).values\n",
    "all_classes = df[10]['Trips'].values\n",
    "print train_all_features,all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "train_labels = keras.utils.to_categorical(df[10]['Trips'][:32], 5)\n",
    "test_labels = keras.utils.to_categorical(df[10]['Trips'][32:], 5)\n",
    "print df[10]['Trips'][:32].argmax()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import ifelse\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 12.2127 - acc: 0.0625 - val_loss: 12.2021 - val_acc: 0.1250\n",
      "Epoch 2/10\n",
      " - 0s - loss: 12.3610 - acc: 0.0313 - val_loss: 12.0180 - val_acc: 0.1250\n",
      "Epoch 3/10\n",
      " - 0s - loss: 12.6467 - acc: 0.0313 - val_loss: 11.9533 - val_acc: 0.1250\n",
      "Epoch 4/10\n",
      " - 0s - loss: 11.5019 - acc: 0.0625 - val_loss: 11.8406 - val_acc: 0.1250\n",
      "Epoch 5/10\n",
      " - 0s - loss: 11.9062 - acc: 0.0625 - val_loss: 11.7995 - val_acc: 0.1250\n",
      "Epoch 6/10\n",
      " - 0s - loss: 12.5976 - acc: 0.0313 - val_loss: 11.7619 - val_acc: 0.1250\n",
      "Epoch 7/10\n",
      " - 0s - loss: 12.7086 - acc: 0.0313 - val_loss: 11.6709 - val_acc: 0.1250\n",
      "Epoch 8/10\n",
      " - 0s - loss: 11.9272 - acc: 0.0313 - val_loss: 11.6244 - val_acc: 0.1250\n",
      "Epoch 9/10\n",
      " - 0s - loss: 11.7910 - acc: 0.0625 - val_loss: 11.5861 - val_acc: 0.1250\n",
      "Epoch 10/10\n",
      " - 0s - loss: 10.8415 - acc: 0.0625 - val_loss: 11.4666 - val_acc: 0.1250\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_all_features, train_labels,\n",
    "                    batch_size=30,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(test_all_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test loss:', 11.466622352600098)\n",
      "('Test accuracy:', 0.125)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_all_features, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n",
      "train\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-17e6a8c27e6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "print test_labels\n",
    "print 'train'\n",
    "print train_x.dtype\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.29223310e-09   2.33744863e-08   3.14844357e-07   9.99622583e-01\n",
      "    3.77006130e-04]]\n",
      "Prediction: 3 Label: 1\n",
      "[[  5.25249419e-12   2.05648068e-10   5.57119284e-09   9.99954820e-01\n",
      "    4.51463420e-05]]\n",
      "Prediction: 3 Label: 1\n",
      "[[  2.71341036e-04   8.74377321e-04   2.47213454e-03   9.55069125e-01\n",
      "    4.13130820e-02]]\n",
      "Prediction: 3 Label: 1\n",
      "[[  3.91552457e-15   4.20918617e-13   2.84421549e-11   9.99997139e-01\n",
      "    2.81081043e-06]]\n",
      "Prediction: 3 Label: 4\n",
      "[[  2.74474559e-07   2.34076288e-06   1.59666433e-05   9.97010708e-01\n",
      "    2.97072181e-03]]\n",
      "[[  2.21982086e-18   6.80846354e-16   1.18806508e-13   9.99999881e-01\n",
      "    1.57467554e-07]]\n",
      "Prediction: 3 Label: 1\n",
      "[[  2.71705836e-09   4.42817694e-08   5.42760972e-07   9.99497294e-01\n",
      "    5.02053939e-04]]\n",
      "Prediction: 3 Label: 1\n",
      "[[  5.91076154e-04   1.70340284e-03   4.35304921e-03   9.38184202e-01\n",
      "    5.51682301e-02]]\n",
      "Prediction: 3 Label: 0\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,8):\n",
    "    test =test_all_features[x].reshape(1,3)\n",
    "    print model.predict(test)\n",
    "    predicted_cat = model.predict(test).argmax()\n",
    "    label = test_labels[x].argmax()\n",
    "    if (predicted_cat != label):\n",
    "        print('Prediction: %d Label: %d' % (predicted_cat, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dow=2\n",
    "current_month = 'Feb'\n",
    "current_day =13\n",
    "isCurrDay_holiday=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeslot 1 :\n",
      "[ 6.31296195  4.          0.        ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 1 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c682bc21877d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mall_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#print train_all_features,all_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#create categorical data df[i]['Trips'][:32].argmax()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trips'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#create categorical data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m#model creation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Lenovo\\Anaconda2\\lib\\site-packages\\keras\\utils\\np_utils.pyc\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
     ]
    }
   ],
   "source": [
    "#Linear Regression module to predict passengers and number of trips\n",
    "import sklearn\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "scale = StandardScaler()    \n",
    "from theano import ifelse\n",
    "total_loss=0\n",
    "total_acc=0\n",
    "\n",
    "err_sum=0\n",
    "trips=[]\n",
    "up_pass=[]\n",
    "\n",
    "# To obtain average error measure across all dataframes\n",
    "for j in xrange(len(timeslot)):\n",
    "    print 'Timeslot',j+1,':'\n",
    "    pass_data=np.asarray(df[j][['Day','isHoliday']])\n",
    "    pass_labels=np.asarray(df[j]['Passengers'])\n",
    "    target=[[current_dow,isCurrDay_holiday]]                      # Example target list to check output format and debugging\n",
    "\n",
    "    passenger_predictor = LinearRegression(normalize=True)          #Linear regression model to predict passenger frequency\n",
    "    passenger_predictor.fit(pass_data, pass_labels)\n",
    "    #err_measure = passenger_predictor.score(pass_data, pass_labels, sample_weight=None)  #Error in passenger frequency prediction\n",
    "    pass_pred=passenger_predictor.predict(target)\n",
    "    up_pass.append(round(pass_pred))\n",
    "    target=np.append(pass_pred,target)\n",
    "    print target                                                    # Target features for predicting number of trips\n",
    "    limit=int(round(0.8*len(df[j])))\n",
    "    train_all_features = df[j][feature_names][:limit].drop(['Trips','Time Slot'], axis=1).values #create training data with trips and time slot dropped\n",
    "    test_all_features=df[j][feature_names][limit:].drop(['Trips','Time Slot'], axis=1).values    #create testing data with trips and time slot dropped\n",
    "    all_classes = df[j]['Trips'].values\n",
    "    #print train_all_features,all_classes\n",
    "    train_labels = keras.utils.to_categorical(df[j]['Trips'][:limit],8) #create categorical data df[i]['Trips'][:32].argmax()\n",
    "    test_labels = keras.utils.to_categorical(df[j]['Trips'][limit:],8)  #create categorical data\n",
    "    #model creation \n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(4, activation='relu', input_shape=(3,)))\n",
    "    #hidden layer\n",
    "    model.add(Dense(2, activation='relu')) \n",
    "    #drop 20% nodes\n",
    "    model.add(Dropout(0.2))\n",
    "    #output layer\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_all_features, train_labels,batch_size=30,epochs=10,verbose=2,\n",
    "                        validation_data=(test_all_features, test_labels))\n",
    "    \n",
    "    score = model.evaluate(test_all_features, test_labels, verbose=0)\n",
    "    total_loss+=score[0]\n",
    "    total_acc+=score[1]\n",
    "    predicted_trips=0\n",
    "\n",
    "    target=target.reshape(1,3)\n",
    "    predicted_trips += model.predict(target).argmax()\n",
    "    trips.append(predicted_trips)\n",
    "    print('Predicted trips for timeslot: %d is: %d' % (j+1,predicted_trips))\n",
    "    \n",
    "for i in range(len(trips)):\n",
    "        if trips[i]=='':\n",
    "            trips[i]=0   \n",
    "trips = [0 if x is None else x for x in trips]\n",
    "    \n",
    "\n",
    "print float(total_loss)/20\n",
    "print float(total_acc)/20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making separate dataframes for each separate timeslot over many days\n",
    "df1=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df2=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df3=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df4=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df5=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df6=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df7=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df8=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df9=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df10=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df11=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df12=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df13=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df14=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df15=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df16=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df17=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df18=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df19=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df20=pd.DataFrame(columns=['Time Slot','Trips','Passengers','Day','isHoliday'])\n",
    "df=[df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17,df18,df19,df20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Timeslot_values= ['00:00:01-05:00:00','05:00:01-06:00:00','06:00:01-07:00:00','07:00:01-08:00:00','08:00:01-09:00:00','09:00:01-10:00:00','10:00:01-11:00:00','11:00:01-12:00:00','12:00:01-13:00:00','13:00:01-14:00:00','14:00:01-15:00:00','15:00:01-16:00:00','16:00:01-17:00:00','17:00:01-18:00:00','18:00:01-19:00:00','19:00:01-20:00:00','20:00:01-21:00:00','21:00:01-22:00:00','22:00:01-23:00:00','23:00:01-24:00:00']\n",
    "Days = {'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}\n",
    "\n",
    "#Obtaining the day and date details for current day \n",
    "now = datetime.datetime.now()   \n",
    "current_month = months[str(now.month).zfill(2)] \n",
    "current_day = now.day\n",
    "isCurrDay_holiday = 0\n",
    "current_dow = Days[now.strftime(\"%A\")]           #Obtaining current day of the week\n",
    "for i in range(1,24):                            #checking if there is holiday today\n",
    "    if(holiday_day[i]==current_day and current_month==holiday_month[i]):\n",
    "        isCurrDay_holiday=1\n",
    "\n",
    "for files in down_allfiles:\n",
    "    #Obtaining Day and date details from filename\n",
    "    base = os.path.basename(files)\n",
    "    base = os.path.basename(files)\n",
    "    day = os.path.splitext(base)[0][31:]\n",
    "    date = os.path.splitext(base)[0][29:31]\n",
    "    month = os.path.splitext(base)[0][26:28]\n",
    "    \n",
    "    #Determining whether holiday or not\n",
    "    year = os.path.splitext(base)[0][21:25]\n",
    "    #Determining whether holiday or not\n",
    "    holiday = 0\n",
    "    if year=='2017':\n",
    "        for i in range(1,22):\n",
    "            if(str(holiday_day_2017[i]).zfill(2)==date and months[month]==holiday_month_2017[i]):\n",
    "            #print'Holiday 2017'\n",
    "                holiday=1\n",
    "    else:\n",
    "        for i in range(1,23):\n",
    "            if(holiday_day[i]==date and months[month]==holiday_month[i]):\n",
    "                holiday=1\n",
    "            \n",
    "    #Pre-processing data into required format\n",
    "    day = Days[day]                                        #Mapping day to numeric value\n",
    "    with open(files,'rb') as f:\n",
    "        timeslot = []\n",
    "        trips = []\n",
    "        passengers = []\n",
    "        reader = csv.reader(f, delimiter=\",\")\n",
    "        rows = [r for r in reader]\n",
    "        for x in rows[1:]:\n",
    "            timeslot.append(x[1])\n",
    "            trips.append(x[2])\n",
    "            if(x[3]==''):\n",
    "                x[3]=0\n",
    "            passengers.append(x[3])\n",
    " \n",
    "    #Adding data into the dataframes created previously according to time slots\n",
    "    for j in xrange(len(timeslot)):\n",
    "        df[j]= df[j].append(pd.Series([timeslot[j],trips[j],int(passengers[j]),day,holiday], index = ['Time Slot','Trips','Passengers','Day','isHoliday']), ignore_index=True)\n",
    "        df[j]=df[j].replace('',0)                      #Replacing NAN values by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeslot 1 :\n",
      "[ 13.7237524   3.          0.       ]\n",
      "Train on 36 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.9025 - acc: 0.6667 - val_loss: 1.9595 - val_acc: 0.4752\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.9138 - acc: 0.7500 - val_loss: 1.9571 - val_acc: 0.6733\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.8602 - acc: 0.7500 - val_loss: 1.9564 - val_acc: 0.9010\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.8697 - acc: 0.8889 - val_loss: 1.9520 - val_acc: 0.9010\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.8776 - acc: 0.8611 - val_loss: 1.9456 - val_acc: 0.9010\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.7914 - acc: 0.9167 - val_loss: 1.9403 - val_acc: 0.9010\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.8719 - acc: 0.8611 - val_loss: 1.9369 - val_acc: 0.9010\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.8121 - acc: 0.9167 - val_loss: 1.9303 - val_acc: 0.9010\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.7712 - acc: 0.8889 - val_loss: 1.9269 - val_acc: 0.9010\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.7968 - acc: 0.8889 - val_loss: 1.9224 - val_acc: 0.9010\n",
      "Predicted trips for timeslot: 1 is: 1\n",
      "Timeslot 2 :\n",
      "[ 12.60718701   3.           0.        ]\n",
      "Train on 36 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.2214 - acc: 0.9167 - val_loss: 1.2514 - val_acc: 0.9109\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.4611 - acc: 0.9167 - val_loss: 1.2317 - val_acc: 0.9109\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.1682 - acc: 0.9167 - val_loss: 1.2154 - val_acc: 0.9109\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.1814 - acc: 0.9167 - val_loss: 1.2014 - val_acc: 0.9109\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.2220 - acc: 0.9167 - val_loss: 1.1859 - val_acc: 0.9109\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.2952 - acc: 0.9167 - val_loss: 1.1718 - val_acc: 0.9109\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.2316 - acc: 0.9167 - val_loss: 1.1576 - val_acc: 0.9109\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.0985 - acc: 0.9167 - val_loss: 1.1453 - val_acc: 0.9109\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.1026 - acc: 0.9167 - val_loss: 1.1323 - val_acc: 0.9109\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.0104 - acc: 0.9167 - val_loss: 1.1182 - val_acc: 0.9109\n",
      "Predicted trips for timeslot: 2 is: 0\n",
      "Timeslot 3 :\n",
      "[ 31.07310657   3.           0.        ]\n",
      "Train on 36 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 4.0769 - acc: 0.1389 - val_loss: 5.2508 - val_acc: 0.4257\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.8916 - acc: 0.3333 - val_loss: 5.2303 - val_acc: 0.4257\n",
      "Epoch 3/10\n",
      " - 0s - loss: 4.5426 - acc: 0.2500 - val_loss: 5.1874 - val_acc: 0.4257\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.7425 - acc: 0.3889 - val_loss: 5.1685 - val_acc: 0.4257\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.7301 - acc: 0.3056 - val_loss: 5.1435 - val_acc: 0.4257\n",
      "Epoch 6/10\n",
      " - 0s - loss: 3.8214 - acc: 0.3333 - val_loss: 5.1190 - val_acc: 0.4257\n",
      "Epoch 7/10\n",
      " - 0s - loss: 3.8725 - acc: 0.1667 - val_loss: 5.1054 - val_acc: 0.4257\n",
      "Epoch 8/10\n",
      " - 0s - loss: 3.2599 - acc: 0.3056 - val_loss: 5.0936 - val_acc: 0.4257\n",
      "Epoch 9/10\n",
      " - 0s - loss: 3.6189 - acc: 0.3611 - val_loss: 5.0645 - val_acc: 0.4257\n",
      "Epoch 10/10\n",
      " - 0s - loss: 3.5758 - acc: 0.3889 - val_loss: 5.0430 - val_acc: 0.4257\n",
      "Predicted trips for timeslot: 3 is: 2\n",
      "Timeslot 4 :\n",
      "[ 119.02057191    3.            0.        ]\n",
      "Train on 36 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 13.4097 - acc: 0.0833 - val_loss: 13.3529 - val_acc: 0.0792\n",
      "Epoch 2/10\n",
      " - 0s - loss: 12.1675 - acc: 0.0833 - val_loss: 13.3047 - val_acc: 0.0792\n",
      "Epoch 3/10\n",
      " - 0s - loss: 12.4723 - acc: 0.0833 - val_loss: 13.2828 - val_acc: 0.0792\n",
      "Epoch 4/10\n",
      " - 0s - loss: 10.5737 - acc: 0.1667 - val_loss: 13.2715 - val_acc: 0.0792\n",
      "Epoch 5/10\n",
      " - 0s - loss: 12.7428 - acc: 0.1389 - val_loss: 13.2555 - val_acc: 0.0792\n",
      "Epoch 6/10\n",
      " - 0s - loss: 13.1038 - acc: 0.0833 - val_loss: 13.2348 - val_acc: 0.0792\n",
      "Epoch 7/10\n",
      " - 0s - loss: 11.9441 - acc: 0.1111 - val_loss: 13.1953 - val_acc: 0.0792\n",
      "Epoch 8/10\n",
      " - 0s - loss: 11.4804 - acc: 0.0556 - val_loss: 13.1783 - val_acc: 0.0792\n",
      "Epoch 9/10\n",
      " - 0s - loss: 11.4992 - acc: 0.1111 - val_loss: 13.1607 - val_acc: 0.0792\n",
      "Epoch 10/10\n",
      " - 0s - loss: 11.5262 - acc: 0.1389 - val_loss: 13.1381 - val_acc: 0.0792\n",
      "Predicted trips for timeslot: 4 is: 0\n",
      "Timeslot 5 :\n",
      "[ 147.12001157    3.            0.        ]\n",
      "Train on 36 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 12.5817 - acc: 0.1667 - val_loss: 14.5652 - val_acc: 0.0495\n",
      "Epoch 2/10\n",
      " - 0s - loss: 10.4285 - acc: 0.1667 - val_loss: 14.5404 - val_acc: 0.0495\n",
      "Epoch 3/10\n",
      " - 0s - loss: 9.9689 - acc: 0.1111 - val_loss: 14.5262 - val_acc: 0.0495\n",
      "Epoch 4/10\n",
      " - 0s - loss: 12.2429 - acc: 0.1111 - val_loss: 14.5039 - val_acc: 0.0495\n",
      "Epoch 5/10\n",
      " - 0s - loss: 11.5644 - acc: 0.0278 - val_loss: 14.4902 - val_acc: 0.0495\n",
      "Epoch 6/10\n",
      " - 0s - loss: 10.5956 - acc: 0.1944 - val_loss: 14.4849 - val_acc: 0.0495\n",
      "Epoch 7/10\n",
      " - 0s - loss: 11.4806 - acc: 0.0833 - val_loss: 14.4776 - val_acc: 0.0495\n",
      "Epoch 8/10\n",
      " - 0s - loss: 10.7447 - acc: 0.1389 - val_loss: 14.4682 - val_acc: 0.0495\n",
      "Epoch 9/10\n",
      " - 0s - loss: 11.9027 - acc: 0.0833 - val_loss: 14.4585 - val_acc: 0.0495\n",
      "Epoch 10/10\n",
      " - 0s - loss: 12.6850 - acc: 0.0833 - val_loss: 14.4454 - val_acc: 0.0495\n",
      "Predicted trips for timeslot: 5 is: 3\n",
      "Timeslot 6 :\n",
      "[ 131.37260937    3.            0.        ]\n",
      "Train on 36 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 12.0619 - acc: 0.0833 - val_loss: 14.3126 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 0s - loss: 12.5240 - acc: 0.0278 - val_loss: 14.3056 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 0s - loss: 12.4031 - acc: 0.1111 - val_loss: 14.2994 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      " - 0s - loss: 10.6467 - acc: 0.0833 - val_loss: 14.2941 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      " - 0s - loss: 12.3264 - acc: 0.0556 - val_loss: 14.2911 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      " - 0s - loss: 12.2569 - acc: 0.0833 - val_loss: 14.2864 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      " - 0s - loss: 11.4448 - acc: 0.1667 - val_loss: 14.2843 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      " - 0s - loss: 11.9072 - acc: 0.1111 - val_loss: 14.2810 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      " - 0s - loss: 11.1094 - acc: 0.1111 - val_loss: 14.2790 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      " - 0s - loss: 12.7294 - acc: 0.0278 - val_loss: 14.2764 - val_acc: 0.0000e+00\n",
      "Predicted trips for timeslot: 6 is: 5\n",
      "Timeslot 7 :\n",
      "[ 125.92990339    3.            0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.2378 - acc: 0.0556 - val_loss: 2.1619 - val_acc: 0.1146\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.1303 - acc: 0.1389 - val_loss: 2.1441 - val_acc: 0.0521\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0928 - acc: 0.0278 - val_loss: 2.1292 - val_acc: 0.0625\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.1187 - acc: 0.0278 - val_loss: 2.1227 - val_acc: 0.0625\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.1369 - acc: 0.1111 - val_loss: 2.1143 - val_acc: 0.0729\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.1610 - acc: 0.0556 - val_loss: 2.1013 - val_acc: 0.1667\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0939 - acc: 0.2222 - val_loss: 2.0966 - val_acc: 0.1875\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.1130 - acc: 0.3333 - val_loss: 2.0935 - val_acc: 0.1667\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.0929 - acc: 0.2222 - val_loss: 2.0913 - val_acc: 0.1563\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.0973 - acc: 0.2500 - val_loss: 2.0857 - val_acc: 0.1667\n",
      "Predicted trips for timeslot: 7 is: 5\n",
      "Timeslot 8 :\n",
      "[ 143.35682993    3.            0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 6.1494 - acc: 0.1389 - val_loss: 9.2847 - val_acc: 0.0104\n",
      "Epoch 2/10\n",
      " - 0s - loss: 5.8841 - acc: 0.0833 - val_loss: 9.1224 - val_acc: 0.0104\n",
      "Epoch 3/10\n",
      " - 0s - loss: 6.3621 - acc: 0.0556 - val_loss: 9.0046 - val_acc: 0.0104\n",
      "Epoch 4/10\n",
      " - 0s - loss: 5.9096 - acc: 0.0556 - val_loss: 8.9080 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      " - 0s - loss: 5.1668 - acc: 0.1389 - val_loss: 8.7474 - val_acc: 0.0104\n",
      "Epoch 6/10\n",
      " - 0s - loss: 5.7079 - acc: 0.1111 - val_loss: 8.6368 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      " - 0s - loss: 4.8665 - acc: 0.1389 - val_loss: 8.4501 - val_acc: 0.0104\n",
      "Epoch 8/10\n",
      " - 0s - loss: 5.4806 - acc: 0.1111 - val_loss: 8.2651 - val_acc: 0.0104\n",
      "Epoch 9/10\n",
      " - 0s - loss: 4.8743 - acc: 0.1389 - val_loss: 8.1034 - val_acc: 0.0104\n",
      "Epoch 10/10\n",
      " - 0s - loss: 5.9971 - acc: 0.0556 - val_loss: 7.9506 - val_acc: 0.0104\n",
      "Predicted trips for timeslot: 8 is: 5\n",
      "Timeslot 9 :\n",
      "[ 138.49415862    3.            0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.5076 - acc: 0.2500 - val_loss: 3.0114 - val_acc: 0.3125\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.6028 - acc: 0.1944 - val_loss: 2.9086 - val_acc: 0.3125\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.4940 - acc: 0.1944 - val_loss: 2.8381 - val_acc: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      " - 0s - loss: 2.3649 - acc: 0.1667 - val_loss: 2.7822 - val_acc: 0.3125\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.3584 - acc: 0.3056 - val_loss: 2.7178 - val_acc: 0.3125\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.3060 - acc: 0.2778 - val_loss: 2.6645 - val_acc: 0.3125\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.1341 - acc: 0.3333 - val_loss: 2.6123 - val_acc: 0.3125\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.1169 - acc: 0.2500 - val_loss: 2.5888 - val_acc: 0.3125\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.2062 - acc: 0.1944 - val_loss: 2.5524 - val_acc: 0.3125\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.2098 - acc: 0.1667 - val_loss: 2.5213 - val_acc: 0.3125\n",
      "Predicted trips for timeslot: 9 is: 2\n",
      "Timeslot 10 :\n",
      "[ 131.17861155    3.            0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.0789 - acc: 0.1667 - val_loss: 2.0740 - val_acc: 0.2292\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.0740 - acc: 0.1111 - val_loss: 2.0712 - val_acc: 0.0208\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0709 - acc: 0.1111 - val_loss: 2.0688 - val_acc: 0.0208\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0680 - acc: 0.2500 - val_loss: 2.0660 - val_acc: 0.4271\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.0655 - acc: 0.4444 - val_loss: 2.0634 - val_acc: 0.4271\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.0632 - acc: 0.4444 - val_loss: 2.0612 - val_acc: 0.4271\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0610 - acc: 0.4444 - val_loss: 2.0591 - val_acc: 0.4271\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.0590 - acc: 0.4444 - val_loss: 2.0568 - val_acc: 0.4271\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.0570 - acc: 0.4444 - val_loss: 2.0549 - val_acc: 0.4271\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.0550 - acc: 0.4444 - val_loss: 2.0530 - val_acc: 0.4271\n",
      "Predicted trips for timeslot: 10 is: 1\n",
      "Timeslot 11 :\n",
      "[ 140.18905864    3.            0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.0977 - acc: 0.2222 - val_loss: 2.1300 - val_acc: 0.1146\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.0912 - acc: 0.2222 - val_loss: 2.1236 - val_acc: 0.4271\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0868 - acc: 0.5000 - val_loss: 2.1186 - val_acc: 0.4271\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0830 - acc: 0.5000 - val_loss: 2.1140 - val_acc: 0.4271\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.0798 - acc: 0.5000 - val_loss: 2.1095 - val_acc: 0.4271\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.0770 - acc: 0.5000 - val_loss: 2.1055 - val_acc: 0.4271\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0743 - acc: 0.5000 - val_loss: 2.1017 - val_acc: 0.4271\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.0716 - acc: 0.5000 - val_loss: 2.0983 - val_acc: 0.4271\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.0690 - acc: 0.5000 - val_loss: 2.0944 - val_acc: 0.4271\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.0663 - acc: 0.5000 - val_loss: 2.0909 - val_acc: 0.4271\n",
      "Predicted trips for timeslot: 11 is: 1\n",
      "Timeslot 12 :\n",
      "[ 129.78173444    3.            0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.9752 - acc: 0.2500 - val_loss: 1.7704 - val_acc: 0.4479\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.6945 - acc: 0.5556 - val_loss: 1.7232 - val_acc: 0.4479\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.5182 - acc: 0.4444 - val_loss: 1.7012 - val_acc: 0.4479\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.5918 - acc: 0.5556 - val_loss: 1.7009 - val_acc: 0.4479\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.6662 - acc: 0.5556 - val_loss: 1.7016 - val_acc: 0.4479\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.5025 - acc: 0.5833 - val_loss: 1.7126 - val_acc: 0.4479\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.4707 - acc: 0.5556 - val_loss: 1.7236 - val_acc: 0.4479\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3588 - acc: 0.5556 - val_loss: 1.7363 - val_acc: 0.4479\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.4847 - acc: 0.5556 - val_loss: 1.7387 - val_acc: 0.4479\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.4436 - acc: 0.5833 - val_loss: 1.7529 - val_acc: 0.4479\n",
      "Predicted trips for timeslot: 12 is: 1\n",
      "Timeslot 13 :\n",
      "[ 95.6390137   3.          0.       ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.0776 - acc: 0.2500 - val_loss: 2.0706 - val_acc: 0.4271\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.0685 - acc: 0.2500 - val_loss: 2.0656 - val_acc: 0.3438\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0609 - acc: 0.5278 - val_loss: 2.0615 - val_acc: 0.4271\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0569 - acc: 0.2222 - val_loss: 2.0584 - val_acc: 0.3438\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.0531 - acc: 0.5278 - val_loss: 2.0555 - val_acc: 0.3438\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.0520 - acc: 0.5278 - val_loss: 2.0525 - val_acc: 0.3438\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0465 - acc: 0.5278 - val_loss: 2.0495 - val_acc: 0.3438\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.0434 - acc: 0.5278 - val_loss: 2.0468 - val_acc: 0.3438\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.0496 - acc: 0.5556 - val_loss: 2.0445 - val_acc: 0.3438\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.0376 - acc: 0.5278 - val_loss: 2.0415 - val_acc: 0.3438\n",
      "Predicted trips for timeslot: 13 is: 1\n",
      "Timeslot 14 :\n",
      "[ 91.8496967   3.          0.       ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.0787 - acc: 0.4167 - val_loss: 2.0712 - val_acc: 0.7188\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.0710 - acc: 0.4722 - val_loss: 2.0661 - val_acc: 0.7188\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0657 - acc: 0.4722 - val_loss: 2.0616 - val_acc: 0.7188\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0614 - acc: 0.4722 - val_loss: 2.0578 - val_acc: 0.7188\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.0574 - acc: 0.4722 - val_loss: 2.0547 - val_acc: 0.2708\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.0538 - acc: 0.5278 - val_loss: 2.0515 - val_acc: 0.2708\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.0504 - acc: 0.5278 - val_loss: 2.0483 - val_acc: 0.2708\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.0471 - acc: 0.5278 - val_loss: 2.0453 - val_acc: 0.2708\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.0439 - acc: 0.5278 - val_loss: 2.0422 - val_acc: 0.2708\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.0408 - acc: 0.5278 - val_loss: 2.0393 - val_acc: 0.2708\n",
      "Predicted trips for timeslot: 14 is: 1\n",
      "Timeslot 15 :\n",
      "[ 66.12873512   3.           0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 1.8364 - acc: 0.2778 - val_loss: 1.7520 - val_acc: 0.1458\n",
      "Epoch 2/10\n",
      " - 0s - loss: 1.8986 - acc: 0.3056 - val_loss: 1.7334 - val_acc: 0.1458\n",
      "Epoch 3/10\n",
      " - 0s - loss: 1.8302 - acc: 0.3056 - val_loss: 1.7289 - val_acc: 0.1458\n",
      "Epoch 4/10\n",
      " - 0s - loss: 1.8617 - acc: 0.3056 - val_loss: 1.7139 - val_acc: 0.1458\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.8503 - acc: 0.4444 - val_loss: 1.7010 - val_acc: 0.1354\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.9265 - acc: 0.5278 - val_loss: 1.7011 - val_acc: 0.1667\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.8977 - acc: 0.3056 - val_loss: 1.6976 - val_acc: 0.1875\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.6956 - acc: 0.3056 - val_loss: 1.6821 - val_acc: 0.1979\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.8121 - acc: 0.2500 - val_loss: 1.6770 - val_acc: 0.2708\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.8874 - acc: 0.3889 - val_loss: 1.6698 - val_acc: 0.3438\n",
      "Predicted trips for timeslot: 15 is: 1\n",
      "Timeslot 16 :\n",
      "[ 34.6497978   3.          0.       ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 5.5944 - acc: 0.3056 - val_loss: 3.6434 - val_acc: 0.3958\n",
      "Epoch 2/10\n",
      " - 0s - loss: 5.6568 - acc: 0.3333 - val_loss: 3.5352 - val_acc: 0.3958\n",
      "Epoch 3/10\n",
      " - 0s - loss: 5.4293 - acc: 0.2778 - val_loss: 3.4513 - val_acc: 0.4063\n",
      "Epoch 4/10\n",
      " - 0s - loss: 5.2513 - acc: 0.3889 - val_loss: 3.3831 - val_acc: 0.4063\n",
      "Epoch 5/10\n",
      " - 0s - loss: 4.8145 - acc: 0.3611 - val_loss: 3.3205 - val_acc: 0.4063\n",
      "Epoch 6/10\n",
      " - 0s - loss: 5.0415 - acc: 0.3889 - val_loss: 3.2381 - val_acc: 0.4063\n",
      "Epoch 7/10\n",
      " - 0s - loss: 5.1806 - acc: 0.3333 - val_loss: 3.1850 - val_acc: 0.4063\n",
      "Epoch 8/10\n",
      " - 0s - loss: 5.0692 - acc: 0.3056 - val_loss: 3.1308 - val_acc: 0.4063\n",
      "Epoch 9/10\n",
      " - 0s - loss: 5.3420 - acc: 0.3056 - val_loss: 3.0778 - val_acc: 0.4063\n",
      "Epoch 10/10\n",
      " - 0s - loss: 5.3138 - acc: 0.2500 - val_loss: 3.0241 - val_acc: 0.4167\n",
      "Predicted trips for timeslot: 16 is: 7\n",
      "Timeslot 17 :\n",
      "[ 25.99977533   3.           0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 3.6982 - acc: 0.5833 - val_loss: 3.3897 - val_acc: 0.6354\n",
      "Epoch 2/10\n",
      " - 0s - loss: 3.5148 - acc: 0.5556 - val_loss: 3.3542 - val_acc: 0.6354\n",
      "Epoch 3/10\n",
      " - 0s - loss: 3.6834 - acc: 0.5833 - val_loss: 3.3276 - val_acc: 0.6354\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.7028 - acc: 0.6111 - val_loss: 3.2989 - val_acc: 0.6354\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.3953 - acc: 0.6667 - val_loss: 3.2554 - val_acc: 0.6354\n",
      "Epoch 6/10\n",
      " - 0s - loss: 3.3125 - acc: 0.5278 - val_loss: 3.2141 - val_acc: 0.6354\n",
      "Epoch 7/10\n",
      " - 0s - loss: 3.2461 - acc: 0.5833 - val_loss: 3.1878 - val_acc: 0.6354\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.6539 - acc: 0.7222 - val_loss: 3.1702 - val_acc: 0.6354\n",
      "Epoch 9/10\n",
      " - 0s - loss: 3.0849 - acc: 0.6111 - val_loss: 3.1482 - val_acc: 0.6354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      " - 0s - loss: 2.9854 - acc: 0.6389 - val_loss: 3.0986 - val_acc: 0.6354\n",
      "Predicted trips for timeslot: 17 is: 0\n",
      "Timeslot 18 :\n",
      "[ 13.54897776   3.           0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.0973 - acc: 0.2778 - val_loss: 2.0607 - val_acc: 0.1771\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.0298 - acc: 0.0833 - val_loss: 2.0150 - val_acc: 0.2813\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.0220 - acc: 0.3056 - val_loss: 1.9904 - val_acc: 0.3229\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.0056 - acc: 0.3056 - val_loss: 1.9369 - val_acc: 0.3229\n",
      "Epoch 5/10\n",
      " - 0s - loss: 1.9560 - acc: 0.3611 - val_loss: 1.9223 - val_acc: 0.3438\n",
      "Epoch 6/10\n",
      " - 0s - loss: 1.9815 - acc: 0.3611 - val_loss: 1.9110 - val_acc: 0.3438\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.8912 - acc: 0.3889 - val_loss: 1.8720 - val_acc: 0.3542\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.8695 - acc: 0.4444 - val_loss: 1.8426 - val_acc: 0.3542\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.8855 - acc: 0.5000 - val_loss: 1.8248 - val_acc: 0.3854\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.9211 - acc: 0.3889 - val_loss: 1.8200 - val_acc: 0.3854\n",
      "Predicted trips for timeslot: 18 is: 0\n",
      "Timeslot 19 :\n",
      "[ 4.44680971  3.          0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 4.2026 - acc: 0.0556 - val_loss: 4.0758 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 0s - loss: 4.5824 - acc: 0.0833 - val_loss: 4.0474 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 0s - loss: 4.1590 - acc: 0.1111 - val_loss: 4.0217 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.3620 - acc: 0.1667 - val_loss: 3.9995 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      " - 0s - loss: 3.7395 - acc: 0.1944 - val_loss: 3.9828 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      " - 0s - loss: 4.1117 - acc: 0.0556 - val_loss: 3.9605 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      " - 0s - loss: 4.4733 - acc: 0.0556 - val_loss: 3.9461 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      " - 0s - loss: 4.0568 - acc: 0.1111 - val_loss: 3.9341 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      " - 0s - loss: 3.6943 - acc: 0.0833 - val_loss: 3.9233 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      " - 0s - loss: 4.0584 - acc: 0.0556 - val_loss: 3.9071 - val_acc: 0.0000e+00\n",
      "Predicted trips for timeslot: 19 is: 4\n",
      "Timeslot 20 :\n",
      "[ 0.58492474  3.          0.        ]\n",
      "Train on 36 samples, validate on 96 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 2.3171 - acc: 0.2500 - val_loss: 2.3405 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 0s - loss: 2.3478 - acc: 0.2778 - val_loss: 2.3144 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 0s - loss: 2.3177 - acc: 0.2222 - val_loss: 2.2926 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      " - 0s - loss: 2.2601 - acc: 0.1667 - val_loss: 2.2720 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.3188 - acc: 0.1944 - val_loss: 2.2556 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.2259 - acc: 0.1944 - val_loss: 2.2439 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      " - 0s - loss: 2.1940 - acc: 0.1944 - val_loss: 2.2318 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      " - 0s - loss: 2.1851 - acc: 0.1944 - val_loss: 2.2166 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      " - 0s - loss: 2.2565 - acc: 0.1667 - val_loss: 2.2005 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      " - 0s - loss: 2.2022 - acc: 0.1944 - val_loss: 2.1893 - val_acc: 0.0000e+00\n",
      "Predicted trips for timeslot: 20 is: 2\n",
      "4.40938867718\n",
      "0.327691831742\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression module to predict passengers and number of trips\n",
    "import sklearn\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "scale = StandardScaler()    \n",
    "from theano import ifelse\n",
    "total_loss=0\n",
    "total_acc=0\n",
    "\n",
    "err_sum=0\n",
    "down_trips=[]\n",
    "down_pass=[]\n",
    "\n",
    "# To obtain average error measure across all dataframes\n",
    "for j in xrange(len(timeslot)):\n",
    "    print 'Timeslot',j+1,':'\n",
    "    pass_data=np.asarray(df[j][['Day','isHoliday']])\n",
    "    pass_labels=np.asarray(df[j]['Passengers'])\n",
    "    target=[[current_dow,isCurrDay_holiday]]                      # Example target list to check output format and debugging\n",
    "\n",
    "    passenger_predictor = LinearRegression(normalize=True)          #Linear regression model to predict passenger frequency\n",
    "    passenger_predictor.fit(pass_data, pass_labels)\n",
    "    #err_measure = passenger_predictor.score(pass_data, pass_labels, sample_weight=None)  #Error in passenger frequency prediction\n",
    "    pass_pred=passenger_predictor.predict(target)\n",
    "    down_pass.append(round(pass_pred))\n",
    "    target=np.append(pass_pred,target)\n",
    "    print target                                                    # Target features for predicting number of trips\n",
    "    train_all_features = df[j][feature_names][:36].drop(['Trips','Time Slot'], axis=1).values #create training data with trips and time slot dropped\n",
    "    test_all_features=df[j][feature_names][36:].drop(['Trips','Time Slot'], axis=1).values    #create testing data with trips and time slot dropped\n",
    "    all_classes = df[j]['Trips'].values\n",
    "    #print train_all_features,all_classes\n",
    "    train_labels = keras.utils.to_categorical(df[j]['Trips'][:36],8) #create categorical data df[i]['Trips'][:32].argmax()\n",
    "    test_labels = keras.utils.to_categorical(df[j]['Trips'][36:],8)  #create categorical data\n",
    "    #model creation \n",
    "    model = Sequential()\n",
    "    #input layer\n",
    "    model.add(Dense(4, activation='relu', input_shape=(3,)))\n",
    "    #hidden layer\n",
    "    model.add(Dense(2, activation='relu')) \n",
    "    #drop 20% nodes\n",
    "    model.add(Dropout(0.2))\n",
    "    #output layer\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_all_features, train_labels,batch_size=30,epochs=10,verbose=2,\n",
    "                        validation_data=(test_all_features, test_labels))\n",
    "    \n",
    "    score = model.evaluate(test_all_features, test_labels, verbose=0)\n",
    "    total_loss+=score[0]\n",
    "    total_acc+=score[1]\n",
    "    predicted_trips=0\n",
    "\n",
    "    target=target.reshape(1,3)\n",
    "    predicted_trips += model.predict(target).argmax()\n",
    "    down_trips.append(predicted_trips)\n",
    "    print('Predicted trips for timeslot: %d is: %d' % (j+1,predicted_trips))\n",
    "    \n",
    "for i in range(len(down_trips)):\n",
    "        if down_trips[i]=='':\n",
    "            down_trips[i]=0   \n",
    "down_trips = [0 if x is None else x for x in down_trips]\n",
    "    \n",
    "\n",
    "print float(total_loss)/20\n",
    "print float(total_acc)/20\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecasted_trips = pd.DataFrame(columns=['Time Slot','Categorical_Trips','Categorical_pass','Categorical_Trips_Down','Categorical_pass_Down'])\n",
    "save_path=r'D:/Dharmit/Final Year Project/Forecasted Trips/'\n",
    "for j in xrange(len(timeslot)):\n",
    "    forecasted_trips= forecasted_trips.append(pd.Series([timeslot[j],trips[j],up_pass[j],down_trips[j],down_pass[j]], index = ['Time Slot','Categorical_Trips','Categorical_pass','Categorical_Trips_Down','Categorical_pass_Down']), ignore_index=True)\n",
    "filename ='Forecasted_trips_'+bus_no+'_'+str(now.month).zfill(2) +'_'+str(now.day)+'_'+str(day)+'_KERAS'\n",
    "forecasted_trips.to_csv(save_path + filename +'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '', '', '2', '2', '2', '1', '1', '1', '2', '2', '1', '0', '0', '0', '0', '0', '0', '', '']\n",
      "[6, 0, 2, 2, 4, 1, 0, 6, 3, 7, 5, 7, 2, 0, 7, 7, 5, 5, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "print trips\n",
    "print down_trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
